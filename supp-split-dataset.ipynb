{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3edbec28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T18:05:20.386775Z",
     "start_time": "2023-06-08T18:05:18.561580Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-tneb8cpq because the default path (/home/jwong/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import random, time, copy\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torchvision import datasets, transforms, models, utils\n",
    "\n",
    "from facenet_pytorch import MTCNN\n",
    "from facenet_pytorch import InceptionResnetV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df304f25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T18:02:50.148489Z",
     "start_time": "2023-06-08T18:02:50.135382Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_dataset(src, dst, range_, class_):\n",
    "    \"\"\"Copy images of class class_ within range_ from src to dst.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    src : str\n",
    "        source directory\n",
    "    dst : str\n",
    "        destination directory\n",
    "    range_ : tuple\n",
    "        tuple of min and max image index to copy\n",
    "    class_ : str\n",
    "        image class \n",
    "    \"\"\"\n",
    "    if os.path.exists(dst):\n",
    "        # if existing, delete dir to reset\n",
    "        shutil.rmtree(dst)\n",
    "    os.makedirs(dst)\n",
    "    fnames = [f'{class_} ({i}).jpg' for i in range(*range_)]\n",
    "    file_names = [image_path for image_path in os.listdir(src)]\n",
    "    \n",
    "    for file_ind, fname in enumerate(fnames):\n",
    "        src_file = os.path.join(src, file_names[file_ind])\n",
    "        dst_file = os.path.join(dst, fname)\n",
    "        shutil.copyfile(src_file, dst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fe18c27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T18:05:00.384998Z",
     "start_time": "2023-06-08T18:04:46.441706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 47 images for Angry.\n",
      "There are 49 images for Sad.\n",
      "There are 48 images for Happy.\n",
      "There are 49 images for Surprise.\n",
      "There are 49 images for Fear.\n",
      "There are 47 images for Disgust.\n",
      "There are 49 images for Neutral.\n",
      "-------------------------\n",
      "Total training images for Angry:  28\n",
      "Total validation images for Angry:  9\n",
      "Total test images for Angry:  10\n",
      "-------------------------\n",
      "Total training images for Sad:  29\n",
      "Total validation images for Sad:  10\n",
      "Total test images for Sad:  10\n",
      "-------------------------\n",
      "Total training images for Happy:  29\n",
      "Total validation images for Happy:  10\n",
      "Total test images for Happy:  9\n",
      "-------------------------\n",
      "Total training images for Surprise:  29\n",
      "Total validation images for Surprise:  10\n",
      "Total test images for Surprise:  10\n",
      "-------------------------\n",
      "Total training images for Fear:  29\n",
      "Total validation images for Fear:  10\n",
      "Total test images for Fear:  10\n",
      "-------------------------\n",
      "Total training images for Disgust:  28\n",
      "Total validation images for Disgust:  9\n",
      "Total test images for Disgust:  10\n",
      "-------------------------\n",
      "Total training images for Neutral:  29\n",
      "Total validation images for Neutral:  10\n",
      "Total test images for Neutral:  10\n",
      "-------------------------\n",
      "Means:           [0.6235189 0.4881056 0.4277293]\n",
      "Std. Deviations: [0.25944903 0.22985741 0.22180712]\n"
     ]
    }
   ],
   "source": [
    "face_classes = ['angry', 'sad', 'happy', 'surprise', 'fear', 'disgust',\n",
    "                'neutral']\n",
    "\n",
    "CROP_DIR = '../datasets/cropped-images'\n",
    "CROP_FILEPATHS = dict()\n",
    "\n",
    "# Number of images per class\n",
    "for face_label in face_classes:\n",
    "    temp_fp = glob.glob(f'{CROP_DIR}/{face_label}/*')\n",
    "    print(f'There are {len(temp_fp)} images for {face_label.title()}.')\n",
    "\n",
    "    CROP_FILEPATHS[face_label] = temp_fp\n",
    "\n",
    "print('-----' * 5)\n",
    "\n",
    "# Specify the train-validation-test partition\n",
    "partition_train = 0.6\n",
    "partition_val = 0.2\n",
    "partition_test = 0.2\n",
    "\n",
    "# Create the train-val-test partition for all classes\n",
    "TRAIN_DIR, VAL_DIR, TEST_DIR = dict(), dict(), dict()\n",
    "\n",
    "for class_ind, class_ in enumerate(face_classes):\n",
    "    train_start = 1\n",
    "    train_end = round(len(CROP_FILEPATHS[class_]) * partition_train) + 1\n",
    "    \n",
    "    val_start = train_end\n",
    "    val_end = val_start + round(len(CROP_FILEPATHS[class_]) * partition_val)\n",
    "    \n",
    "    test_start = val_end\n",
    "    test_end = len(CROP_FILEPATHS[class_]) + 1\n",
    "    \n",
    "    train_dest = f'data/classifier/train/{class_}' # train directory\n",
    "    TRAIN_DIR[class_] = train_dest\n",
    "    create_dataset(f'{CROP_DIR}/{class_}', train_dest, \n",
    "                   range_=(train_start, train_end), class_=class_)\n",
    "    \n",
    "    val_dest = f'data/classifier/validation/{class_}' # val directory\n",
    "    VAL_DIR[class_] = val_dest\n",
    "    create_dataset(f'{CROP_DIR}/{class_}', val_dest, \n",
    "                   range_=(val_start, val_end), class_=class_)\n",
    "    \n",
    "    test_dest = f'data/classifier/test/{class_}' # test directory\n",
    "    TEST_DIR[class_] = test_dest\n",
    "    create_dataset(f'{CROP_DIR}/{class_}', test_dest, \n",
    "                   range_=(test_start, test_end), class_=class_)\n",
    "    \n",
    "    print(f'Total training images for {class_.title()}: ',\n",
    "          len(os.listdir(TRAIN_DIR[class_])))\n",
    "    \n",
    "    print(f'Total validation images for {class_.title()}: ',\n",
    "          len(os.listdir(VAL_DIR[class_])))\n",
    "    \n",
    "    print(f'Total test images for {class_.title()}: ',\n",
    "          len(os.listdir(TEST_DIR[class_])))\n",
    "    \n",
    "    print('-----' * 5)\n",
    "TRAIN_FDIR = \"data/classifier/train\"\n",
    "\n",
    "# Resizing the images\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(root=TRAIN_FDIR,\n",
    "                                  transform=data_transforms)\n",
    "\n",
    "# Compute for the means and stds (for normalization)\n",
    "imgs = torch.stack([img_t for img_t, _ in train_data], dim=3)\n",
    "means = imgs.view(3, -1).mean(dim=1).numpy()\n",
    "stds = imgs.view(3, -1).std(dim=1).numpy()\n",
    "\n",
    "print(f'Means:           {means}') \n",
    "print(f'Std. Deviations: {stds}')\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(size=(224,224)),\n",
    "        transforms.RandomHorizontalFlip(p=0.6),             \n",
    "        transforms.RandomPerspective(p=0.5),\n",
    "        transforms.ColorJitter(brightness=0.5),              \n",
    "        transforms.ToTensor(),                              \n",
    "        transforms.Normalize(means, stds)\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Resize(size=(224,224)),\n",
    "        transforms.ToTensor(),                              \n",
    "        transforms.Normalize(means, stds)\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(size=(224,224)),\n",
    "        transforms.ToTensor(),                              \n",
    "        transforms.Normalize(means, stds)\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n",
    "DATA_DIR = 'data/classifier'\n",
    "\n",
    "# Loading image data using ImageFolder\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(DATA_DIR, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'validation', 'test']}\n",
    "\n",
    "# Dataloaders\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=4,\n",
    "                             shuffle=True, drop_last=True)\n",
    "              for x in ['train', 'validation', 'test']}\n",
    "\n",
    "# Size of datasets\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in\n",
    "                 ['train', 'validation', 'test']}\n",
    "\n",
    "# Class names\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad00c1db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T18:05:56.052703Z",
     "start_time": "2023-06-08T18:05:44.869643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means:           [0.6235189 0.4881056 0.4277293]\n",
      "Std. Deviations: [0.25944903 0.22985741 0.22180712]\n"
     ]
    }
   ],
   "source": [
    "TRAIN_FDIR = \"data/classifier/train\"\n",
    "\n",
    "# Resizing the images\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(root=TRAIN_FDIR,\n",
    "                                  transform=data_transforms)\n",
    "\n",
    "# Compute for the means and stds (for normalization)\n",
    "imgs = torch.stack([img_t for img_t, _ in train_data], dim=3)\n",
    "means = imgs.view(3, -1).mean(dim=1).numpy()\n",
    "stds = imgs.view(3, -1).std(dim=1).numpy()\n",
    "\n",
    "print(f'Means:           {means}') \n",
    "print(f'Std. Deviations: {stds}')\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(size=(224,224)),\n",
    "        transforms.RandomHorizontalFlip(p=0.6),             \n",
    "        transforms.RandomPerspective(p=0.5),\n",
    "        transforms.ColorJitter(brightness=0.5),              \n",
    "        transforms.ToTensor(),                              \n",
    "        transforms.Normalize(means, stds)\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Resize(size=(224,224)),\n",
    "        transforms.ToTensor(),                              \n",
    "        transforms.Normalize(means, stds)\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(size=(224,224)),\n",
    "        transforms.ToTensor(),                              \n",
    "        transforms.Normalize(means, stds)\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n",
    "DATA_DIR = 'data/classifier'\n",
    "\n",
    "# Loading image data using ImageFolder\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(DATA_DIR, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'validation', 'test']}\n",
    "\n",
    "# Dataloaders\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=4,\n",
    "                             shuffle=True, drop_last=True)\n",
    "              for x in ['train', 'validation', 'test']}\n",
    "\n",
    "# Size of datasets\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in\n",
    "                 ['train', 'validation', 'test']}\n",
    "\n",
    "# Class names\n",
    "class_names = image_datasets['train'].classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
